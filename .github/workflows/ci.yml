name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  GO_VERSION: '1.24.6'  # Latest stable Go version
  CGO_ENABLED: 0

jobs:
  prepare:
    name: Prepare Dependencies
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Download dependencies
      run: go mod download

    - name: Install and run mockery to generate mocks
      run: |
        go install github.com/vektra/mockery/v2@latest
        mockery --all --inpackage --with-expecter=true

    - name: Cache generated mocks
      uses: actions/cache@v4
      with:
        path: ./**/*mock*.go
        key: mocks-${{ hashFiles('**/go.sum', 'internal/**/*.go', 'pkg/**/*.go') }}
        restore-keys: |
          mocks-

  test:
    name: Test
    runs-on: ubuntu-latest
    needs: [prepare]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Restore Go modules cache
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Restore mocks cache
      uses: actions/cache@v4
      with:
        path: ./**/*mock*.go
        key: mocks-${{ hashFiles('**/go.sum', 'internal/**/*.go', 'pkg/**/*.go') }}
        restore-keys: |
          mocks-

    - name: Download dependencies
      run: go mod download

    - name: Regenerate mocks if cache miss
      run: |
        if [ ! -f "internal/domain/parser/mock_ParserOption.go" ]; then
          go install github.com/vektra/mockery/v2@latest
          mockery --all --inpackage --with-expecter=true
        fi

    - name: Run tests
      env:
        CGO_ENABLED: 1
      run: go test -v -race -coverprofile=coverage.out ./internal/... ./pkg/...

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v5
      with:
        file: ./coverage.out
        flags: unittests
        name: codecov-umbrella

  lint:
    name: Lint
    runs-on: ubuntu-latest
    needs: [prepare]  # Use shared preparation job
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Restore Go modules cache
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Restore mocks cache
      uses: actions/cache@v4
      with:
        path: ./**/*mock*.go
        key: mocks-${{ hashFiles('**/go.sum', 'internal/**/*.go', 'pkg/**/*.go') }}
        restore-keys: |
          mocks-

    - name: Download Go modules
      run: go mod download

    - name: Regenerate mocks if cache miss
      run: |
        if [ ! -f "internal/domain/parser/mock_ParserOption.go" ]; then
          go install github.com/vektra/mockery/v2@latest
          mockery --all --inpackage --with-expecter=true
        fi

    - name: Install golangci-lint
      uses: golangci/golangci-lint-action@v7
      with:
        version: latest
        args: --timeout=5m

  frontend-test:
    name: Frontend Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: web/package-lock.json

    - name: Install frontend dependencies
      run: |
        cd web
        npm ci

    - name: Run frontend tests with coverage
      run: |
        cd web
        npm run test:coverage

    - name: Upload frontend test coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./web/coverage/coverage-final.json
        flags: frontend
        name: frontend-coverage
        directory: ./web

  frontend-lint:
    name: Frontend Lint & Type Check
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: web/package-lock.json

    - name: Install frontend dependencies
      run: |
        cd web
        npm ci

    - name: Run ESLint
      run: |
        cd web
        npm run lint

    - name: Run TypeScript type checking
      run: |
        cd web
        npm run type-check

    - name: Check for unused dependencies
      run: |
        cd web
        npx depcheck --ignores="@types/*,@typescript-eslint/*,@vitejs/*,@testing-library/*,tailwindcss*,postcss*,autoprefixer,prettier*,@vitest/coverage-v8,wait-on"

  frontend-build:
    name: Frontend Build
    runs-on: ubuntu-latest
    needs: [frontend-test, frontend-lint]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: web/package-lock.json

    - name: Install frontend dependencies
      run: |
        cd web
        npm ci

    - name: Build frontend for production
      run: |
        cd web
        # Use CI build to skip TypeScript checking (checked separately)
        npm run build:ci

    - name: Analyze bundle size
      run: |
        cd web
        echo "📦 Bundle Analysis" > bundle-analysis.txt
        echo "==================" >> bundle-analysis.txt
        echo "" >> bundle-analysis.txt
        
        # Calculate total bundle size
        TOTAL_SIZE=$(find dist/assets -name "*.js" -o -name "*.css" | xargs wc -c | tail -1 | awk '{print $1}')
        TOTAL_SIZE_KB=$((TOTAL_SIZE / 1024))
        echo "Total bundle size: ${TOTAL_SIZE_KB} KB" >> bundle-analysis.txt
        echo "" >> bundle-analysis.txt
        
        # List individual files
        echo "Individual assets:" >> bundle-analysis.txt
        ls -lh dist/assets/ >> bundle-analysis.txt
        echo "" >> bundle-analysis.txt
        
        # Check for large files
        echo "Files over 100KB:" >> bundle-analysis.txt
        find dist/assets -size +100k -ls >> bundle-analysis.txt || echo "No files over 100KB" >> bundle-analysis.txt
        
        cat bundle-analysis.txt

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: frontend-build
        path: |
          web/dist/
          web/bundle-analysis.txt
        retention-days: 7

  frontend-e2e:
    name: Frontend E2E Tests
    runs-on: ubuntu-latest
    needs: [frontend-build]
    if: false  # Disabled until backend HTTP server is implemented
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: web/package-lock.json

    - name: Install frontend dependencies
      run: |
        cd web
        npm ci

    - name: Install Playwright
      run: |
        cd web
        npx playwright install --with-deps

    - name: Download frontend build
      uses: actions/download-artifact@v5
      with:
        name: frontend-build
        path: web/dist/



    - name: Start preview server
      run: |
        cd web
        # Start preview server in background
        npm run preview > preview.log 2>&1 &
        
        # Wait for server to be ready with timeout
        timeout 60s npx wait-on http://localhost:4173 --timeout 60000 || {
          echo "Preview server failed to start within 60 seconds"
          echo "Preview server logs:"
          cat preview.log
          exit 1
        }
        
        echo "Preview server is ready at http://localhost:4173"

    - name: Run E2E tests
      run: |
        cd web
        # Run E2E tests with timeout to prevent hanging
        timeout 10m npx playwright test --timeout=300000

    - name: Stop preview server
      if: always()
      run: |
        cd web
        # Kill any remaining preview processes
        pkill -f "npm run preview" 2>/dev/null || true
        pkill -f "vite preview" 2>/dev/null || true

    - name: Upload E2E test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: e2e-test-results
        path: web/test-results/
        retention-days: 7

  test-quality-report:
    name: Test Quality Report
    runs-on: ubuntu-latest
    needs: [test, frontend-test, frontend-lint]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download Go coverage
      uses: actions/download-artifact@v5
      continue-on-error: true  # Coverage artifacts may not exist if tests failed
      with:
        name: go-coverage
        path: ./go-coverage/

    - name: Download frontend coverage
      uses: actions/download-artifact@v5  
      continue-on-error: true  # Coverage artifacts may not exist if tests failed
      with:
        name: frontend-coverage
        path: ./web/coverage/

    - name: Generate comprehensive test report
      run: |
        echo "# Test Quality Report" > test-report.md
        echo "" >> test-report.md
        echo "**APIWeaver Test Results**" >> test-report.md
        echo "" >> test-report.md
        echo "Generated on: $(date)" >> test-report.md
        echo "Commit: ${{ github.sha }}" >> test-report.md
        echo "Workflow: ${{ github.run_number }}" >> test-report.md
        echo "" >> test-report.md
        
        # Backend test results
        echo "## 🔧 Backend Tests" >> test-report.md
        if [ "${{ needs.test.result }}" = "success" ]; then
          echo "✅ **Go Tests**: PASSED" >> test-report.md
        else
          echo "❌ **Go Tests**: FAILED" >> test-report.md
        fi
        echo "" >> test-report.md
        
        # Frontend test results  
        echo "## 🎨 Frontend Tests" >> test-report.md
        if [ "${{ needs.frontend-test.result }}" = "success" ]; then
          echo "✅ **Frontend Unit Tests**: PASSED" >> test-report.md
        else
          echo "❌ **Frontend Unit Tests**: FAILED" >> test-report.md
        fi
        
        if [ "${{ needs.frontend-lint.result }}" = "success" ]; then
          echo "✅ **Frontend Lint & Type Check**: PASSED" >> test-report.md
        else
          echo "❌ **Frontend Lint & Type Check**: FAILED" >> test-report.md
        fi
        echo "" >> test-report.md
        
        # Test coverage summary
        echo "## 📊 Test Coverage Summary" >> test-report.md
        echo "" >> test-report.md
        
        if [ -f "coverage.out" ]; then
          GO_COVERAGE=$(go tool cover -func=coverage.out | grep total | awk '{print $3}')
          echo "- **Go Coverage**: $GO_COVERAGE" >> test-report.md
        else
          echo "- **Go Coverage**: Not available" >> test-report.md
        fi
        
        if [ -f "web/coverage/coverage-summary.json" ]; then
          FRONTEND_COVERAGE=$(cat web/coverage/coverage-summary.json | jq -r '.total.lines.pct + "%"' 2>/dev/null || echo "N/A")
          echo "- **Frontend Coverage**: $FRONTEND_COVERAGE" >> test-report.md
        else
          echo "- **Frontend Coverage**: Not available" >> test-report.md
        fi
        echo "" >> test-report.md
        
        # Test statistics
        echo "## 📈 Test Statistics" >> test-report.md
        echo "" >> test-report.md
        echo "| Component | Status | Coverage | Notes |" >> test-report.md
        echo "|-----------|--------|----------|-------|" >> test-report.md
        
        if [ "${{ needs.test.result }}" = "success" ]; then
          TEST_STATUS="✅ Passed"
        else
          TEST_STATUS="❌ Failed"
        fi
        echo "| Go Backend | $TEST_STATUS | ${GO_COVERAGE:-N/A} | Go tests with race detection |" >> test-report.md
        
        if [ "${{ needs.frontend-test.result }}" = "success" ]; then
          FRONTEND_STATUS="✅ Passed"
        else
          FRONTEND_STATUS="❌ Failed"
        fi
        echo "| React Frontend | $FRONTEND_STATUS | ${FRONTEND_COVERAGE:-N/A} | Vitest + React Testing Library |" >> test-report.md
        
        if [ "${{ needs.frontend-lint.result }}" = "success" ]; then
          LINT_STATUS="✅ Passed"
        else
          LINT_STATUS="❌ Failed"
        fi
        echo "| Code Quality | $LINT_STATUS | N/A | ESLint + TypeScript |" >> test-report.md
        echo "" >> test-report.md
        
        # Overall assessment
        FAILED_JOBS=0
        [ "${{ needs.test.result }}" != "success" ] && FAILED_JOBS=$((FAILED_JOBS + 1))
        [ "${{ needs.frontend-test.result }}" != "success" ] && FAILED_JOBS=$((FAILED_JOBS + 1))  
        [ "${{ needs.frontend-lint.result }}" != "success" ] && FAILED_JOBS=$((FAILED_JOBS + 1))
        
        echo "## 🎯 Overall Assessment" >> test-report.md
        echo "" >> test-report.md
        if [ $FAILED_JOBS -eq 0 ]; then
          echo "🟢 **All tests passed successfully!** The codebase is ready for deployment." >> test-report.md
        elif [ $FAILED_JOBS -eq 1 ]; then
          echo "🟡 **1 test suite failed.** Review the failing tests before deployment." >> test-report.md
        else
          echo "🔴 **$FAILED_JOBS test suites failed.** Address failing tests before proceeding." >> test-report.md
        fi
        echo "" >> test-report.md
        
        echo "---" >> test-report.md
        echo "*Report generated by APIWeaver CI pipeline*" >> test-report.md
        
        cat test-report.md

    - name: Upload test quality report
      uses: actions/upload-artifact@v4
      with:
        name: test-quality-report
        path: test-report.md

  # Integration tests and spec validation will be added when the API server is implemented

  build:
    name: Build
    runs-on: ubuntu-latest
    needs: [test, lint, frontend-build]  # Wait for backend and frontend validation
    
    strategy:
      matrix:
        goos: [linux, darwin]
        goarch: [amd64, arm64]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-build-${{ matrix.goos }}-${{ matrix.goarch }}-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-build-${{ matrix.goos }}-${{ matrix.goarch }}-
          ${{ runner.os }}-go-

    - name: Download Go modules
      run: go mod download

    - name: Debug directory structure
      run: |
        echo "Current directory: $(pwd)"
        echo "Directory contents:"
        ls -la
        echo "cmd directory contents:"
        ls -la cmd/ || echo "cmd directory not found"
        echo "cmd/apiweaver directory contents:"
        ls -la cmd/apiweaver/ || echo "cmd/apiweaver directory not found"

    - name: Build for ${{ matrix.goos }}/${{ matrix.goarch }}
      env:
        GOOS: ${{ matrix.goos }}
        GOARCH: ${{ matrix.goarch }}
        CGO_ENABLED: 0
      run: go build -ldflags="-s -w" -o "apiweaver-${{ matrix.goos }}-${{ matrix.goarch }}" ./cmd/apiweaver

    - name: Set artifact path
      run: echo "ARTIFACT_PATH=apiweaver-${{ matrix.goos }}-${{ matrix.goarch }}" >> "$GITHUB_ENV"

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: apiweaver-${{ matrix.goos }}-${{ matrix.goarch }}
        path: ${{ env.ARTIFACT_PATH }}

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: [prepare]  # Use shared preparation job
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Restore Go modules cache
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Download Go modules
      run: go mod download

    - name: Run Go vulnerability check
      run: |
        go install golang.org/x/vuln/cmd/govulncheck@latest
        govulncheck ./...

